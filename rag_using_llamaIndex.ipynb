{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG using LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (4.52.4)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl.metadata (439 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.42 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.42-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.4.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.86.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (3.12.13)\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (2025.5.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (2.1.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (2.32.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.42->llama-index) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (9.1.2)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.42->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.42->llama-index) (1.20.1)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.42->llama-index)\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.42->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.42->llama-index) (4.3.8)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.42->llama-index) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.42->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.42->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.42->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.42->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.42->llama-index) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.42->llama-index) (0.4.6)\n",
      "Requirement already satisfied: ollama>=0.5.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-index-llms-ollama) (0.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.32-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.42->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.42->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.42->llama-index) (3.2.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.42->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.42->llama-index) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.42->llama-index) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\1034960\\desktop\\akshara\\study_material\\myprojects\\aiprojects\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading llama_index-0.12.42-py3-none-any.whl (7.1 kB)\n",
      "Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_cli-0.4.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.42-py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.7 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 3.4/7.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 17.5 MB/s eta 0:00:00\n",
      "Using cached banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_llms_openai-0.4.6-py3-none-any.whl (25 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
      "Using cached llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
      "Using cached llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading openai-1.86.0-py3-none-any.whl (730 kB)\n",
      "   ---------------------------------------- 0.0/730.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 730.3/730.3 kB 14.6 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl (8.1 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl (8.9 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
      "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.32-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.32-py3-none-any.whl (39 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, tzdata, soupsieve, pypdf, jiter, griffe, distro, deprecated, click, aiosqlite, tiktoken, pandas, nltk, beautifulsoup4, openai, llama-cloud, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-ollama, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-embeddings-huggingface, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   -- -------------------------------------  2/36 [filetype]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ---- -----------------------------------  4/36 [tzdata]\n",
      "   ----- ----------------------------------  5/36 [soupsieve]\n",
      "   ------ ---------------------------------  6/36 [pypdf]\n",
      "   ------ ---------------------------------  6/36 [pypdf]\n",
      "   ------- --------------------------------  7/36 [jiter]\n",
      "   -------- -------------------------------  8/36 [griffe]\n",
      "   -------- -------------------------------  8/36 [griffe]\n",
      "   ------------ --------------------------- 11/36 [click]\n",
      "   -------------- ------------------------- 13/36 [tiktoken]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   --------------- ------------------------ 14/36 [pandas]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ---------------- ----------------------- 15/36 [nltk]\n",
      "   ----------------- ---------------------- 16/36 [beautifulsoup4]\n",
      "   ----------------- ---------------------- 16/36 [beautifulsoup4]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   ------------------ --------------------- 17/36 [openai]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   -------------------- ------------------- 18/36 [llama-cloud]\n",
      "   --------------------- ------------------ 19/36 [banks]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ---------------------- ----------------- 20/36 [llama-index-core]\n",
      "   ----------------------- ---------------- 21/36 [llama-index-readers-file]\n",
      "   ------------------------ --------------- 22/36 [llama-index-llms-openai]\n",
      "   ---------------------------- ----------- 26/36 [llama-cloud-services]\n",
      "   ------------------------------ --------- 27/36 [llama-parse]\n",
      "   ------------------------------ --------- 27/36 [llama-parse]\n",
      "   --------------------------------- ------ 30/36 [llama-index-cli]\n",
      "   ------------------------------------ --- 33/36 [llama-index-program-openai]\n",
      "   -------------------------------------- - 35/36 [llama-index]\n",
      "   -------------------------------------- - 35/36 [llama-index]\n",
      "   ---------------------------------------- 36/36 [llama-index]\n",
      "\n",
      "Successfully installed aiosqlite-0.21.0 banks-2.1.2 beautifulsoup4-4.13.4 click-8.2.1 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 griffe-1.7.3 jiter-0.10.0 llama-cloud-0.1.26 llama-cloud-services-0.6.32 llama-index-0.12.42 llama-index-agent-openai-0.4.11 llama-index-cli-0.4.3 llama-index-core-0.12.42 llama-index-embeddings-huggingface-0.5.4 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-llms-ollama-0.6.2 llama-index-llms-openai-0.4.6 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.32 nltk-3.9.1 openai-1.86.0 pandas-2.2.3 pypdf-5.6.0 pytz-2025.2 soupsieve-2.7 striprtf-0.0.26 tiktoken-0.9.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index llama-index-llms-ollama llama-index-embeddings-huggingface sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"phi\",\n",
    "    temperature=0.7)\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='73a7ac6a-c4de-472c-b295-13c8aa5e0c87', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\1034960\\\\Desktop\\\\Akshara\\\\study_material\\\\MyProjects\\\\AIprojects\\\\data\\\\food.txt', 'file_name': 'food.txt', 'file_type': 'text/plain', 'file_size': 1473, 'creation_date': '2025-06-14', 'last_modified_date': '2025-06-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Food Item: Apple\\r\\nCategory: Fruit\\r\\nDescription: Apples are sweet, edible fruits produced by an apple tree. They are rich in fiber and vitamin C.\\r\\nNutritional Info (per 100g): Calories: 52, Carbs: 14g, Fiber: 2.4g, Sugar: 10g, Protein: 0.3g\\r\\n\\r\\nFood Item: Broccoli\\r\\nCategory: Vegetable\\r\\nDescription: Broccoli is a cruciferous vegetable known for its high levels of vitamin C, K, and fiber. Often eaten steamed or raw.\\r\\nNutritional Info (per 100g): Calories: 34, Carbs: 7g, Fiber: 2.6g, Protein: 2.8g\\r\\n\\r\\nFood Item: Chicken Breast\\r\\nCategory: Protein\\r\\nDescription: A lean cut of chicken meat, commonly used in healthy diets. It is a great source of protein and low in fat.\\r\\nNutritional Info (per 100g): Calories: 165, Protein: 31g, Fat: 3.6g, Carbs: 0g\\r\\n\\r\\nFood Item: Almonds\\r\\nCategory: Nuts\\r\\nDescription: Almonds are nutrient-dense nuts packed with healthy fats, vitamin E, magnesium, and antioxidants.\\r\\nNutritional Info (per 100g): Calories: 579, Protein: 21g, Fat: 50g, Carbs: 22g, Fiber: 12g\\r\\n\\r\\nFood Item: Brown Rice\\r\\nCategory: Grain\\r\\nDescription: Brown rice is a whole grain with the bran and germ intact, making it more nutritious than white rice.\\r\\nNutritional Info (per 100g): Calories: 123, Carbs: 26g, Fiber: 1.6g, Protein: 2.7g\\r\\n\\r\\nFood Item: Yogurt (Plain)\\r\\nCategory: Dairy\\r\\nDescription: Yogurt is a fermented milk product rich in probiotics, calcium, and protein. Great for gut health.\\r\\nNutritional Info (per 100g): Calories: 59, Protein: 10g, Carbs: 3.6g, Fat: 0.4g\\r\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "index = VectorStoreIndex.from_documents(documents, llm=llm, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the above information, you can recommend chicken breast and almonds to be a good source of protein.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core  import PromptTemplate\n",
    "\n",
    "source_aware_prompt = PromptTemplate(\n",
    "    \"\"\"\n",
    "    You are a nutrition assistant. Answer based on the food document context provided.\n",
    "    \n",
    "    Context from food documents:\n",
    "    {context_str}\n",
    "    \n",
    "    Question: {query_str}\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    text_qa_template=source_aware_prompt\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"suggest protein rich foods?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, you can include chicken breast (30g protein per 100g), broccoli (2g protein per 100g) and almonds (21g protein per 100g) in your diet. \n",
      "\n",
      "    To incorporate fiber into your diet, add brown rice (4g of fiber per 100g) or yogurt (3g of fiber per 100g).\n",
      "\n",
      "Answer: The suggested foods are chicken breast, broccoli, almonds, and brown rice (or yogurt). You can combine them to create a balanced diet plan. \n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Create a diet plan which includes proteins and fiber?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
